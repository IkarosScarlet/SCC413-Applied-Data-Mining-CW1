# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16_1sM36kMV7cu4wZsVSvpGFexdamQ5QX
"""

#!/usr/bin/env python
# coding: utf-8

# ### Test on ECG Data

# The dataset you will use is based on one from [timeseriesclassification.com](http://www.timeseriesclassification.com/description.php?Dataset=ECG5000).
# 
# Try to design and train your MLP to classify normal and abnormal ECG samples.

# In[ ]:


import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import tensorflow as tf

from sklearn.metrics import accuracy_score, precision_score, recall_score
from sklearn.model_selection import train_test_split
from tensorflow.keras import layers, losses
from tensorflow.keras.datasets import fashion_mnist
from tensorflow.keras.models import Model

# Download the dataset
dataframe = pd.read_csv('http://storage.googleapis.com/download.tensorflow.org/data/ecg.csv', header=None)
raw_data = dataframe.values
dataframe.head()


# In[ ]:


# The last element contains the labels
labels = raw_data[:, -1]

# The other data points are the electrocadriogram data
data = raw_data[:, 0:-1]

train_data, test_data, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=21)

# Normalize to [0, 1]
min_val = tf.reduce_min(train_data)
max_val = tf.reduce_max(train_data)

train_data = (train_data - min_val) / (max_val - min_val)
test_data = (test_data - min_val) / (max_val - min_val)

# train_data = tf.cast(train_data, tf.float32)
# test_data = tf.cast(test_data, tf.float32)
x_train = tf.cast(train_data, tf.float32)
x_test = tf.cast(test_data, tf.float32)


# plot data
plt.grid()
plt.plot(np.arange(140), train_data[0])
plt.show()


# In[ ]:


plt.grid()
plt.plot(np.arange(140), train_data[100])
plt.show()


# More about the dataset from the link,
# "The original dataset for "ECG5000" is a 20-hour long ECG downloaded from Physionet. The name is BIDMC Congestive Heart Failure Database(chfdb) and it is record "chf07". It was originally published in "Goldberger AL, Amaral LAN, Glass L, Hausdorff JM, Ivanov PCh, Mark RG, Mietus JE, Moody GB, Peng C-K, Stanley HE. PhysioBank, PhysioToolkit, and PhysioNet: Components of a New Research Resource for Complex Physiologic Signals. Circulation 101(23)". The data was pre-processed in two steps: (1) extract each heartbeat, (2) make each heartbeat equal length using interpolation. This dataset was originally used in paper "A general framework for never-ending learning from time series streams", DAMI 29(6). After that, 5,000 heartbeats were randomly selected. The patient has severe congestive heart failure and the class values were obtained by automated annotation"
# 
# See [link dataset](http://www.timeseriesclassification.com/description.php?Dataset=ECG5000)

#####built model
from keras.models import Sequential
from keras.layers.core import Dense, Dropout, Activation
from keras.layers.embeddings import Embedding
from keras.layers.recurrent import SimpleRNN
 
model = Sequential()
 
model.add(Embedding(output_dim=32,
                    input_dim=3800, 
                    input_length=380))
model.add(Dropout(0.35))
 
model.add(SimpleRNN(units=16))
 
model.add(Dense(units=256,activation='relu' ))
 
model.add(Dropout(0.35))
 
model.add(Dense(units=1,activation='sigmoid' ))
 
model.summary()
 
#####train model
model.compile(loss='binary_crossentropy', 
              optimizer='adam', 
              metrics=['accuracy'])
 
train_history =model.fit(x_train, y_train,batch_size=100, 
                         epochs=10,verbose=2,
                         validation_split=0.2)
 
import matplotlib.pyplot as plt
def show_train_history(train_history,train,validation):
    plt.plot(train_history.history[train])
    plt.plot(train_history.history[validation])
    plt.title('Train History')
    plt.ylabel(train)
    plt.xlabel('Epoch')
    plt.legend(['train', 'validation'], loc='upper left')
    plt.show()
 
# show_train_history(train_history,'acc','val_acc')
# show_train_history(train_history,'loss','val_loss')
 
#####Evaluate the accuracy of the model
scores = model.evaluate(x_test, y_test, verbose=1)
scores[1]
 
#####The forecast probability
probility=model.predict(x_test)
probility[:10]
 
for p in probility[12500:12510]:
    print(p)
 
#####forecast results
predict=model.predict_classes(x_test)
 
predict[:10]
predict.shape

predicted = np.reshape(predict, (predict.size,))
 
#####View the forecast results
SentimentDict={1:'1',0:'0'}
def display_test_Sentiment(i):
    print(test_text[i])
    print('label true values:',SentimentDict[y_test[i]],
          'predict results:',SentimentDict[predict_classes[i]])

